---
lang: 'en'
slug: '/786F87'
aliases: ["Let's Alter"]
---

## Ongoing Subprojects

- [ ] Perceptual Hashing On Device: [phash.wasm](./../.././docs/pages/phash.wasm.md)

## TODO

- [ ] PlanetScale Federated Server to store `hash → text`
- [ ] Inference Server to `image → text`. AWS SageMaker? Or [Hugging Face](./../.././docs/pages/Hugging%20Face.md) as an API server?
- [ ] Inference Server stores that data to Federated Server
- [ ] imgbot app

### Resources

- [Letter to Mr. Matt Rickard on 2022-11-28](./../.././docs/pages/Letter%20to%20Mr.%20Matt%20Rickard%20on%202022-11-28.md)
- [Comparing BLIP and CLIP](./../.././docs/pages/Comparing%20BLIP%20and%20CLIP.md)
- [Example References for Alter](./../.././docs/pages/Example%20References%20for%20Alter.md)
- [salesforce/BLIP: PyTorch code for BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://github.com/salesforce/BLIP)
- [openai/CLIP: Contrastive Language-Image Pretraining](https://github.com/openai/CLIP)
- [CLIP: Connecting Text and Images](https://openai.com/blog/clip/)
- Vision Transforms (ViT)
- [CLIP Interrogator - a Hugging Face Space by pharma](https://huggingface.co/spaces/pharma/CLIP-Interrogator)

<head>
  <html lang="en-US"/>
</head>
