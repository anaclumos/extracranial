---
date: '2024-07-01'
lang: 'en'
slug: '/2024-07-01'
---

- DP → 데이터를 gpu에 분산하는 것을 0번 gpu에서 함.
- ddp → gradient update 사항만 공유함. 각각 노드에서 미니배치를 알아서 함. 데이터를 공유하지는 않음. torch.distributed라는 제공되는 라이브러리에서. 서로 통신하기 위해서 ip를 가지고 있어야 하는데, 우리는 master ip만 가지고 있음. rank 0, 1, 2, 3번이 있고 마스터에서 뿌려줌. 토치에서 ip 테이블을 실제로 만들어줌.)
- Sharded DP

SetupTask는 DDP인 경우에 특화된 행동들을 정의하기 위해서 존재함

VM이 꺼질 때 shutdown script가 있음. 백엔드에 shutdown call을 날림.

마스터 노드의 차이는: 중앙이 관리를 하고 나머지는 개별 작업을 한다.
