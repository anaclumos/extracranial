---

lang: 'en'
slug: '/C62BBE'

---

[[Case Study]] of [[Humane Ai Pin]]

## [Process - Wayfinding with Ai Pin](https://michaelandzanes.website/process)

### Pocket-sized projector

![[6A21D1.png]]

- Used a Pico projector.
- Took the projector outside to film our concepts and showcase how they could work.

### Architecture

![[A8FEC4.png]]

- Hypothesized that [[Humane Ai Pin|Ai Pin]] could utilize a MEMS blue laser scanner
  - small size, energy efficiency, and always-in-focus capabilities.
- Projected images on our hands and developed guidelines for positioning and scaling [[UIUX|UI]] elements.

### Font and line weights

![[F7D97E.png]]

- Created tests to find which fonts, line weights, and shapes were ideal for legibility under bright and dark environments to understand laser projectors better.

### [[Iterative and Incremental Development|Iterative]] prototyping

![[FB5B85.gif]]

- The demo shows a compass arrow that adjusts its perspective based on your hand position.
- Used tools like Figma, Origami, and Keynote

### Inspiration

![[4CD57A.png]]

- Light Phone II is designed as a communication tool that reduces distractions.
- Inspired by its interface and tried projecting it as an early experiment.

### One-handed operation

![[DEE740.gif]]

- [[Humane Ai Pin|Ai Pin]] should still work with one hand.
- This example shows how you could return to a dashboard or "home" state by closing your palm.
- This correlates with you "closing" an activity.

### Primary gestures

![[8CE4FB.gif]]

- We would like to know if you could display interface elements on your fingertips that could be easily tapped.
- This solution feels ergonomically friendly.
- Not sure if the hardware will be able to project onto a target this small

### Common interactions

![[B47ACF.gif]]

- We tested our interaction mechanisms on common visual elements such as lists.
- This demo explores scrolling lists using a two-handed gesture.
- The interfaces we pursued for this concept reduced the need to scroll by displaying minimal information.

### [[Animation|Animations]] and haptics

![[308AC8.gif]]

- Multi-modal feedback —visual cues, sound, and haptics— would be critical for Wayfinding.
- Built [[Animation|animations]] to work alongside the potential hardware to demonstrate these scenarios.

### Ambient awareness

![[402F83.gif]]

- A future iteration of the hardware may be able to listen to announcements.
- [[Humane Ai Pin|Ai Pin]] could transcribe and alert you about relevant trip updates.

### Dynamic, contextually aware interface

![[242382.gif]]

- Seamlessly transition and adapt based on understanding your surroundings.
- Less manual control, more intelligent interface, without interaction
