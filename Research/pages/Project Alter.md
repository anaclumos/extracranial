---
lang: 'en'
slug: '/786F87'
---

- [[Letter to Mr. Matt Rickard on 2022-11-28]]
- [[Comparing BLIP and CLIP]]
- [[Example References for Alter]]

## TODO

- [ ] Perceptual Hashing On Device
- [ ] PlanetScale Federated Server to store `hash → text`
- [ ] Inference Server to `image → text`. AWS SageMaker? Or [[Hugging Face]] as an API server?
- [ ] Inference Server stores that data to Federated Server
- [ ] imgbot app

### Resources

- [salesforce/BLIP: PyTorch code for BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://github.com/salesforce/BLIP)
- [openai/CLIP: Contrastive Language-Image Pretraining](https://github.com/openai/CLIP)
- [CLIP: Connecting Text and Images](https://openai.com/blog/clip/)
- Vision Transforms (ViT)
- [CLIP Interrogator - a Hugging Face Space by pharma](https://huggingface.co/spaces/pharma/CLIP-Interrogator)
