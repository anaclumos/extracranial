---
lang: 'ko'
slug: '/7E5BF0'
---

[WebGPU](https://gpuweb.github.io/gpuweb/)는 렌더링 및 계산 작업 등을 처리하는 Direct3D 12, Metal, Vulkan과 같은 현대 GPU 기능에 접근할 수 있는 API이다. WebGL과 비슷하지만, 더 발전된 GPU 기능에 접근할 수 있다.
WebGL은 주로 이미지를 그리기 위해 설계되었고 다른 용도를 사용하기 위해서는 상당한 노력을 해야하지만, WebGPU는 GPU에서 할 수 있는 일반적인 계산들을 전부 지원한다.
**만약 이걸 [[NPU]]에도 똑같이 할 수 있다면 어떨까?**
가상의 API, **WebNPU**를 제안한다.
한줄로 설명해보자면:

- [[WebAssembly]]는 웹에서 [[CPU]]의 온전한 성능을 개방한다.
- [[WebGPU]]는 웹에서 [[GPU]]의 온전한 성능을 개방한다.
- **WebNPU**는 웹에서 [[NPU]]의 온전한 성능을 개방한다.

우리는 이미 애플의 [[Neural Engine]]으로 온디바이스 ML 기술의 시작을 관찰하고 있다. 여기에는 단순한 Siri 명령에서 완전한 [Stable Diffusion](https://github.com/apple/ml-stable-diffusion) 모델에 이르기까지 다양한 작업이 포함된다. 물론 서버 규모 대규모 ML에 비해 성능은 약하지만, 레이턴시나 개인 정보 보호의 면에서 훨씬 우수하다. 구글 등의 다른 회사들도 [텐서](https://blog.google/products/pixel/introuting-google-tensor/)와 같은 칩을 개발하며 따라잡고 있다. 불행하게도 지금까지 이 칩들은 네이티브 애플리케이션을 통해서만 접근할 수 있다. 웹 플랫폼의 경우 [TensorFlow.js](https://www.tensorflow.org/js)와 같은 아주 높은 추상화 레벨로만 CPU에서 겨우 실행이 가능하다.

언젠가 AI 네이티브(우리 클라우드 네이티브처럼)가 표준이 되면, 특히 웹 기술을 사용하여 [[NPU]]에 액세스하기 위한 API를 요구하는 목소리가 점점 커질 것이다. 이는 모두에게 좋은 일인데...

- **소비자**. 모든 것이 로컬로 빠르고 안전하다. 미래에는 인공지능을 서비스의 더 다양한 분야에 적용할텐데, 특정화된 인공지능 서비스를 위해 앱을 설치할 필요가 없다. 웹사이트를 방문하는 것으로 충분하다.
- **개발자**. 인공지능 서비스를 출시하기 위해 추론 서버를 생성할 필요가 없다. WebNPU는 또한 개발자들이 [[Write Once Run Everywhere]]를 이루어주기 때문에 개발 프로세스를 단순화할 수 있다.
- **회사**. 앞으로 규제와 제약으로 인해 데이터를 수집하는 것은 점점 더 어려워질 것이다. WebNPU는 그 필요성을 없앤다. WebNPU는 AI 작업을 사용자 장치에서 수행할 수 있어 서버의 부하를 줄이고 회사가 서비스를 더 쉽게 확장할 수 있다.
- **하드웨어 개발사**. 웹[[NPU]]는 AI 작업에 최적화된 전문 하드웨어를 개발해 기기 제조사와 다른 고객에게 판매할 새로운 사업 기회를 제공한다.
- **정부**. WebNPU는 AI 작업을 사용자 장치에서 로컬로 수행할 수 있도록 하여 네트워크를 통해 전송해야 하는 데이터 양을 줄이고 잠재적으로 데이터 침해 및 기타 보안 문제의 위험을 줄임으로써 개인 정보 보호 및 보안 문제를 해결하는 데 도움이 될 수 있다. 이를 통해 규제 기관은 데이터가 책임감 있고 안전한 방식으로 처리되도록 보장할 수 있다.

다만 우리가 아직 AI 초기라는 점에 주목해야한다. 하드웨어 공급업체마다 접근 방식과 요구 사항이 다르기 때문에 [[NPU]]를 구축하는 구체적인 표준화된 방법이 없다. 예를 들어 코어 ML은 Core ML 모델을 사용하는 반면 텐서플로 라이트는 FlatBuffer 모델을 사용한다. 아무래도 우리는 [[VP9 vs HEVC]] 또는 [[USDZ vs glTF]]의 싸움처럼 애플과 구글의 싸움을 다시 보게 될 것 같다.
